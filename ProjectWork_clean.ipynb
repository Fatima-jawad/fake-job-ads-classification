{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake Job Postings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries used\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk \n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, LancasterStemmer\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, roc_auc_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler#, OneHotEncoder \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll now upload the preprocessed\n",
    "df_pre = pd.read_csv('fake_job_postings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>title</th>\n",
       "      <th>location</th>\n",
       "      <th>department</th>\n",
       "      <th>salary_range</th>\n",
       "      <th>company_profile</th>\n",
       "      <th>description</th>\n",
       "      <th>requirements</th>\n",
       "      <th>benefits</th>\n",
       "      <th>telecommuting</th>\n",
       "      <th>has_company_logo</th>\n",
       "      <th>has_questions</th>\n",
       "      <th>employment_type</th>\n",
       "      <th>required_experience</th>\n",
       "      <th>required_education</th>\n",
       "      <th>industry</th>\n",
       "      <th>function</th>\n",
       "      <th>fraudulent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Marketing Intern</td>\n",
       "      <td>US, NY, New York</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We're Food52, and we've created a groundbreaki...</td>\n",
       "      <td>Food52, a fast-growing, James Beard Award-winn...</td>\n",
       "      <td>Experience with content management systems a m...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Other</td>\n",
       "      <td>Internship</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marketing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Customer Service - Cloud Video Production</td>\n",
       "      <td>NZ, , Auckland</td>\n",
       "      <td>Success</td>\n",
       "      <td>NaN</td>\n",
       "      <td>90 Seconds, the worlds Cloud Video Production ...</td>\n",
       "      <td>Organised - Focused - Vibrant - Awesome!Do you...</td>\n",
       "      <td>What we expect from you:Your key responsibilit...</td>\n",
       "      <td>What you will get from usThrough being part of...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Full-time</td>\n",
       "      <td>Not Applicable</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Marketing and Advertising</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   job_id                                      title          location  \\\n",
       "0       1                           Marketing Intern  US, NY, New York   \n",
       "1       2  Customer Service - Cloud Video Production    NZ, , Auckland   \n",
       "\n",
       "  department salary_range                                    company_profile  \\\n",
       "0  Marketing          NaN  We're Food52, and we've created a groundbreaki...   \n",
       "1    Success          NaN  90 Seconds, the worlds Cloud Video Production ...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Food52, a fast-growing, James Beard Award-winn...   \n",
       "1  Organised - Focused - Vibrant - Awesome!Do you...   \n",
       "\n",
       "                                        requirements  \\\n",
       "0  Experience with content management systems a m...   \n",
       "1  What we expect from you:Your key responsibilit...   \n",
       "\n",
       "                                            benefits  telecommuting  \\\n",
       "0                                                NaN              0   \n",
       "1  What you will get from usThrough being part of...              0   \n",
       "\n",
       "   has_company_logo  has_questions employment_type required_experience  \\\n",
       "0                 1              0           Other          Internship   \n",
       "1                 1              0       Full-time      Not Applicable   \n",
       "\n",
       "  required_education                   industry          function  fraudulent  \n",
       "0                NaN                        NaN         Marketing           0  \n",
       "1                NaN  Marketing and Advertising  Customer Service           0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pre.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['job_id', 'title', 'location', 'department', 'salary_range',\n",
       "       'company_profile', 'description', 'requirements', 'benefits',\n",
       "       'telecommuting', 'has_company_logo', 'has_questions', 'employment_type',\n",
       "       'required_experience', 'required_education', 'industry', 'function',\n",
       "       'fraudulent'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pre.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll select the textual data to use in training\n",
    "df = df_pre[['company_profile','description','requirements','benefits','fraudulent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original:           (17880, 5) (866, 5) (17014, 5)\n",
      "description:        (17879, 5) (865, 5) (17014, 5)\n",
      "company_profile:    (14572, 5) (279, 5) (14293, 5)\n",
      "requirements:       (15185, 5) (712, 5) (14473, 5)\n",
      "benefits:           (10670, 5) (502, 5) (10168, 5)\n",
      "All:                (17880, 5) (866, 5) (17014, 5)\n"
     ]
    }
   ],
   "source": [
    "a = df[~df.description.isna()]\n",
    "b = df[~df.company_profile.isna()] \n",
    "c = df[~df.requirements.isna()]\n",
    "d = df[~df.benefits.isna()]\n",
    "e = df[~df.isna()]\n",
    "print('Original:          ',df.shape, df[df.fraudulent == 1].shape, df[df.fraudulent == 0].shape)\n",
    "print('description:       ',a.shape, a[a.fraudulent == 1].shape, a[a.fraudulent == 0].shape)\n",
    "print('company_profile:   ',b.shape, b[b.fraudulent == 1].shape, b[b.fraudulent == 0].shape)\n",
    "print('requirements:      ',c.shape, c[c.fraudulent == 1].shape, c[c.fraudulent == 0].shape)\n",
    "print('benefits:          ',d.shape, d[d.fraudulent == 1].shape, d[d.fraudulent == 0].shape)\n",
    "print('All:               ',e.shape, e[e.fraudulent == 1].shape, e[e.fraudulent == 0].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to be carefull when selecting which columns to process and how to deal with Nans to avoid significant drop in minority data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets fill the nan values with 'Missing'\n",
    "df.fillna('Missing', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets drop all stop words and stem our words and get it tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PorterStemmer does not often generate stems that are actual English words. It does not keep a lookup table for actual stems of the word but applies algorithmic rules to generate stems. It uses the rules to decide whether it is wise to strip a suffix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LancasterStemmer (Paice-Husk stemmer) is an iterative algorithm with rules saved externally. One table containing about 120 rules indexed by the last letter of a suffix. On each iteration, it tries to find an applicable rule by the last character of the word. Each rule specifies either a deletion or replacement of an ending. If there is no such rule, it terminates. It also terminates if a word starts with a vowel and there are only two letters left or if a word starts with a consonant and there are only three characters left. Otherwise, the rule is applied, and the process repeats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_profile</th>\n",
       "      <th>description</th>\n",
       "      <th>requirements</th>\n",
       "      <th>benefits</th>\n",
       "      <th>fraudulent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we're food52, and we've created a groundbreaki...</td>\n",
       "      <td>food52, a fast-growing, james beard award-winn...</td>\n",
       "      <td>experience with content management systems a m...</td>\n",
       "      <td>missing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>90 seconds, the worlds cloud video production ...</td>\n",
       "      <td>organised - focused - vibrant - awesome!do you...</td>\n",
       "      <td>what we expect from you:your key responsibilit...</td>\n",
       "      <td>what you will get from usthrough being part of...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>valor services provides workforce solutions th...</td>\n",
       "      <td>our client, located in houston, is actively se...</td>\n",
       "      <td>implement pre-commissioning and commissioning ...</td>\n",
       "      <td>missing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>our passion for improving quality of life thro...</td>\n",
       "      <td>the company: esri – environmental systems rese...</td>\n",
       "      <td>education: bachelor’s or master’s in gis, busi...</td>\n",
       "      <td>our culture is anything but corporate—we have ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spotsource solutions llc is a global human cap...</td>\n",
       "      <td>job title: itemization review managerlocation:...</td>\n",
       "      <td>qualifications:rn license in the state of texa...</td>\n",
       "      <td>full benefits offered</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17875</th>\n",
       "      <td>vend is looking for some awesome new talent to...</td>\n",
       "      <td>just in case this is the first time you’ve vis...</td>\n",
       "      <td>to ace this role you:will eat comprehensive st...</td>\n",
       "      <td>what can you expect from us?we have an open cu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17876</th>\n",
       "      <td>weblinc is the e-commerce platform and service...</td>\n",
       "      <td>the payroll accountant will focus primarily on...</td>\n",
       "      <td>- b.a. or b.s. in accounting- desire to have f...</td>\n",
       "      <td>health &amp;amp; wellnessmedical planprescription ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17877</th>\n",
       "      <td>we provide full time permanent positions for m...</td>\n",
       "      <td>experienced project cost control staff enginee...</td>\n",
       "      <td>at least 12 years professional experience.abil...</td>\n",
       "      <td>missing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17878</th>\n",
       "      <td>missing</td>\n",
       "      <td>nemsia studios is looking for an experienced v...</td>\n",
       "      <td>1. must be fluent in the latest versions of co...</td>\n",
       "      <td>competitive salary (compensation will be based...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17879</th>\n",
       "      <td>vend is looking for some awesome new talent to...</td>\n",
       "      <td>who are we?vend is an award winning web based ...</td>\n",
       "      <td>we want to hear from you if:you have an in-dep...</td>\n",
       "      <td>missing</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17880 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         company_profile  \\\n",
       "0      we're food52, and we've created a groundbreaki...   \n",
       "1      90 seconds, the worlds cloud video production ...   \n",
       "2      valor services provides workforce solutions th...   \n",
       "3      our passion for improving quality of life thro...   \n",
       "4      spotsource solutions llc is a global human cap...   \n",
       "...                                                  ...   \n",
       "17875  vend is looking for some awesome new talent to...   \n",
       "17876  weblinc is the e-commerce platform and service...   \n",
       "17877  we provide full time permanent positions for m...   \n",
       "17878                                            missing   \n",
       "17879  vend is looking for some awesome new talent to...   \n",
       "\n",
       "                                             description  \\\n",
       "0      food52, a fast-growing, james beard award-winn...   \n",
       "1      organised - focused - vibrant - awesome!do you...   \n",
       "2      our client, located in houston, is actively se...   \n",
       "3      the company: esri – environmental systems rese...   \n",
       "4      job title: itemization review managerlocation:...   \n",
       "...                                                  ...   \n",
       "17875  just in case this is the first time you’ve vis...   \n",
       "17876  the payroll accountant will focus primarily on...   \n",
       "17877  experienced project cost control staff enginee...   \n",
       "17878  nemsia studios is looking for an experienced v...   \n",
       "17879  who are we?vend is an award winning web based ...   \n",
       "\n",
       "                                            requirements  \\\n",
       "0      experience with content management systems a m...   \n",
       "1      what we expect from you:your key responsibilit...   \n",
       "2      implement pre-commissioning and commissioning ...   \n",
       "3      education: bachelor’s or master’s in gis, busi...   \n",
       "4      qualifications:rn license in the state of texa...   \n",
       "...                                                  ...   \n",
       "17875  to ace this role you:will eat comprehensive st...   \n",
       "17876  - b.a. or b.s. in accounting- desire to have f...   \n",
       "17877  at least 12 years professional experience.abil...   \n",
       "17878  1. must be fluent in the latest versions of co...   \n",
       "17879  we want to hear from you if:you have an in-dep...   \n",
       "\n",
       "                                                benefits fraudulent  \n",
       "0                                                missing          0  \n",
       "1      what you will get from usthrough being part of...          0  \n",
       "2                                                missing          0  \n",
       "3      our culture is anything but corporate—we have ...          0  \n",
       "4                                  full benefits offered          0  \n",
       "...                                                  ...        ...  \n",
       "17875  what can you expect from us?we have an open cu...          0  \n",
       "17876  health &amp; wellnessmedical planprescription ...          0  \n",
       "17877                                            missing          0  \n",
       "17878  competitive salary (compensation will be based...          0  \n",
       "17879                                            missing          0  \n",
       "\n",
       "[17880 rows x 5 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will first convert all texts to lowercase \n",
    "df.apply(lambda x: x.astype(str).str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "lancaster=LancasterStemmer()\n",
    "stops = set(stopwords.words(\"english\"))\n",
    "\n",
    "def identify_tokens(row):\n",
    "    review = row\n",
    "    tokens = nltk.word_tokenize(review)\n",
    "    token_words = [w for w in tokens if w.isalpha()]\n",
    "    meaningful_words = [w for w in token_words if not w in stops]\n",
    "    stemmed_list = [lancaster.stem(word) for word in meaningful_words]\n",
    "    joined_words = (' '.join(stemmed_list))\n",
    "    \n",
    "    return joined_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed_company_profile'] = df['company_profile'].apply(identify_tokens)\n",
    "df['processed_description'] = df['description'].apply(identify_tokens)\n",
    "df['processed_requirements'] = df['requirements'].apply(identify_tokens)\n",
    "df['processed_benefits'] = df['benefits'].apply(identify_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Cleaned_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['company_profile', 'description', 'requirements', 'benefits',\n",
       "       'fraudulent', 'processed_company_profile', 'processed_description',\n",
       "       'processed_requirements', 'processed_benefits'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['fraudulent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # TRY THIS AGAIN\n",
    "# tfidf = TfidfVectorizer(decode_error='ignore')\n",
    "# X = tfidf.fit_transform(df[['processed_company_profile',\n",
    "#                             'processed_description',\n",
    "#                             'processed_requirements',\n",
    "#                             'processed_benefits']].values.reshape(1,-1).astype('str'))\n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(decode_error='ignore')\n",
    "X1 = tfidf.fit_transform(df['processed_company_profile'].values.astype('str'))\n",
    "X2 = tfidf.fit_transform(df['processed_description'].values.astype('str'))\n",
    "X3 = tfidf.fit_transform(df['processed_requirements'].values.astype('str'))\n",
    "X4 = tfidf.fit_transform(df['processed_benefits'].values.astype('str'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create functions for our models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Model\n",
    "\n",
    "def log_reg_model(X_train, X_test, y_train, y_test):\n",
    "    model = LogisticRegression(max_iter=10000)\n",
    "    \n",
    "#     param_grid = {'penalty' : ['l1', 'l2', 'elasticnet', 'none'],\n",
    "#                   'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "#                   'C':range(1,1000)}\n",
    "    param_grid = {'C':range(1,1000)}\n",
    "    grid = GridSearchCV(model, param_grid, cv=10, scoring='recall')\n",
    "    tqdm(grid.fit(X_train, y_train))\n",
    "    \n",
    "    print(\"Best params:       \", grid.best_params_)\n",
    "    print(\"Best estimator:    \", grid.best_estimator_)\n",
    "    print(\"Best score:        \", grid.best_score_)\n",
    "    \n",
    "    final_model = grid.best_estimator_\n",
    "    y_pred = final_model.predict(X_test)\n",
    "    \n",
    "    print('Score:             ', final_model.score(X_train, y_train))\n",
    "    print('roc_auc_score:     ', roc_auc_score(y_test, y_pred))\n",
    "    print('precision_score:   ', precision_score(y_test, y_pred))\n",
    "    print('accuracy_score:    ', accuracy_score(y_test, y_pred))\n",
    "    print('recall_score:      ', recall_score(y_test, y_pred))\n",
    "    print('f1_score:          ', f1_score(y_test, y_pred))\n",
    "    \n",
    "    #return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_model(X_train, X_test, y_train, y_test):\n",
    "    model = KNeighborsClassifier()\n",
    "    k_range = list(range(1, 101))\n",
    "    weight_options = ['uniform', 'distance']\n",
    "    \n",
    "    param_grid = dict(n_neighbors=k_range, weights=weight_options)\n",
    "    \n",
    "    grid = GridSearchCV(model, param_grid, cv=10, scoring='recall')\n",
    "    grid.fit(X_train, y_train)\n",
    "    \n",
    "    print(\"Best params: \", grid.best_params_)\n",
    "    print(\"Best estimator: \", grid.best_estimator_)\n",
    "    print(\"Best score: \", grid.best_score_)\n",
    "    \n",
    "    knn = grid.best_estimator_\n",
    "    y_pred = knn.predict(X_test)\n",
    "    \n",
    "    print('Score             :', knn.score(X_train, y_train))\n",
    "    print('roc_auc_score     :', roc_auc_score(y_test, y_pred))\n",
    "    print('precision_score   :', precision_score(y_test, y_pred))\n",
    "    print('accuracy_score    :', accuracy_score(y_test, y_pred))\n",
    "    print('recall_score      :', recall_score(y_test, y_pred))\n",
    "    print('f1_score          :', f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def D_T_C_model(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    dtc = DecisionTreeClassifier().fit(X_train,y_train)\n",
    "    y_pred = dtc.predict(X_test)\n",
    "    \n",
    "    print('Score             :', dtc.score(X_train, y_train))\n",
    "    print('roc_auc_score     :', roc_auc_score(y_test, y_pred))\n",
    "    print('precision_score   :', precision_score(y_test, y_pred))\n",
    "    print('accuracy_score    :', accuracy_score(y_test, y_pred))\n",
    "    print('recall_score      :', recall_score(y_test, y_pred))\n",
    "    print('f1_score          :', f1_score(y_test, y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def R_F_C_model(X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    rfc = RandomForestClassifier(n_estimators=100).fit(X_train,y_train)\n",
    "    y_pred = rfc.predict(X_test)\n",
    "    \n",
    "    print('Score             :', rfc.score(X_train, y_train))\n",
    "    print('roc_auc_score     :', roc_auc_score(y_test, y_pred))\n",
    "    print('precision_score   :', precision_score(y_test, y_pred))\n",
    "    print('accuracy_score    :', accuracy_score(y_test, y_pred))\n",
    "    print('recall_score      :', recall_score(y_test, y_pred))\n",
    "    print('f1_score          :', f1_score(y_test, y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying company_profile (X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X1, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score             : 0.9668624161073825\n",
      "roc_auc_score     : 0.6450617283950617\n",
      "precision_score   : 1.0\n",
      "accuracy_score    : 0.9678411633109619\n",
      "recall_score      : 0.29012345679012347\n",
      "f1_score          : 0.44976076555023925\n"
     ]
    }
   ],
   "source": [
    "D_T_C_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score             : 0.9667925055928411\n",
      "roc_auc_score     : 0.6512345679012346\n",
      "precision_score   : 1.0\n",
      "accuracy_score    : 0.968400447427293\n",
      "recall_score      : 0.30246913580246915\n",
      "f1_score          : 0.46445497630331756\n"
     ]
    }
   ],
   "source": [
    "R_F_C_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying description (X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X2, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score             : 0.9999300894854586\n",
      "roc_auc_score     : 0.7775912838633687\n",
      "precision_score   : 0.723404255319149\n",
      "accuracy_score    : 0.9672818791946308\n",
      "recall_score      : 0.5666666666666667\n",
      "f1_score          : 0.6355140186915887\n"
     ]
    }
   ],
   "source": [
    "D_T_C_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R_F_C_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying requirements (X3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X3, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score             : 0.990981543624161\n",
      "roc_auc_score     : 0.7356473879462385\n",
      "precision_score   : 0.6829268292682927\n",
      "accuracy_score    : 0.9639261744966443\n",
      "recall_score      : 0.4827586206896552\n",
      "f1_score          : 0.5656565656565657\n"
     ]
    }
   ],
   "source": [
    "D_T_C_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score             : 0.990981543624161\n",
      "roc_auc_score     : 0.7182438322285066\n",
      "precision_score   : 0.987012987012987\n",
      "accuracy_score    : 0.9723154362416108\n",
      "recall_score      : 0.4367816091954023\n",
      "f1_score          : 0.6055776892430279\n"
     ]
    }
   ],
   "source": [
    "R_F_C_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying benefits (X4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X4, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score             : 0.9778383668903803\n",
      "roc_auc_score     : 0.7287684439973173\n",
      "precision_score   : 0.7722772277227723\n",
      "accuracy_score    : 0.968400447427293\n",
      "recall_score      : 0.4642857142857143\n",
      "f1_score          : 0.5799256505576209\n"
     ]
    }
   ],
   "source": [
    "D_T_C_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score             : 0.9778383668903803\n",
      "roc_auc_score     : 0.7309691482226693\n",
      "precision_score   : 0.9069767441860465\n",
      "accuracy_score    : 0.9725950782997763\n",
      "recall_score      : 0.4642857142857143\n",
      "f1_score          : 0.6141732283464567\n"
     ]
    }
   ],
   "source": [
    "R_F_C_model(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add features together, get best compination\n",
    "# Add features from df_pre\n",
    "# Try different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
